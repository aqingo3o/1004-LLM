{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea403f80",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f4607",
   "metadata": {},
   "source": [
    "**pytorch**是python的一個程式庫，就像是處理天文數據會用astropy那樣，**pytorch**是專門拿來開發AI的工具，可想像成可以被GPU加速的numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa02593e",
   "metadata": {},
   "source": [
    "有二大特點，使其能夠很好的作為深度學習的框架：\n",
    "1. 利用 **張量(tensor)** 作為處理資料的基本單位，並且可被丟到GPU上面做數學運算\n",
    "2. **自動微分引擎(Autograd)**：我們在寫程式只要定義好forward要怎麼算，系統就會自動幫我們紀錄路徑，再透過連鎖律算出所有參數的微分，從而修正模型參數"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62af3a4",
   "metadata": {},
   "source": [
    "# 前置準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f063965a",
   "metadata": {},
   "source": [
    "函式庫更新可能追不上python版本更新，所以建議使用比最新版本低1-2版本的python(我是用3.10)；有CUDA相容的GPU的建議就安裝支援GPU的版本，嘗試看看用GPU跑程式  \n",
    "PS: CUDA是個運算平台，負責*指揮*GPU去看懂程式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9677b6ce",
   "metadata": {},
   "source": [
    "關於要在terminal打甚麼指令安裝pytorch，因為每個人系統不一樣，因此請見官網：\n",
    "`https://pytorch.org/`  \n",
    "然後這邊採用PyTorch 2.4.0，所以建議把指令的torch改成`torch==2.4.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55536c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c9229e",
   "metadata": {},
   "source": [
    "# 張量簡介"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d717c",
   "metadata": {},
   "source": [
    "- 0階張量: scalar\n",
    "- 1階張量: vector\n",
    "- 2階張量: Matrix\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acfd68a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0D Tensor:\n",
      "tensor(1)\n",
      "torch.Size([])\n",
      "\n",
      "\n",
      "1D Tensor:\n",
      "tensor([1, 2, 3])\n",
      "torch.Size([3])\n",
      "\n",
      "\n",
      "2D Tensor:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([2, 3])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a tensor\n",
    "tensor_0d = torch.tensor(1)\n",
    "tensor_1d = torch.tensor([1, 2, 3])\n",
    "tensor_2d = torch.tensor([[1, 2, 3],\n",
    "                          [4, 5, 6]])\n",
    "\n",
    "for i in range(3):\n",
    "    if i == 0:\n",
    "        tensor = tensor_0d\n",
    "    elif i == 1:\n",
    "        tensor = tensor_1d\n",
    "    else:\n",
    "        tensor = tensor_2d\n",
    "    print(f\"{i}D Tensor:\", tensor,tensor.shape,\"\\n\",sep=\"\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc5cec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]]) \n",
      "\n",
      " tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# from the output, we can see that the 2D tensor has shape (2, 3),\n",
    "# if we want to reshape it to (3, 2), we can do as follows:\n",
    "\n",
    "# reshape tensors(take 2D tensor as example)\n",
    "tensor = tensor_2d\n",
    "\n",
    "# there are two ways to reshape a tensor\n",
    "# 1. using reshape() method\n",
    "re_tensor_1 = tensor.reshape(3, 2)\n",
    "\n",
    "# 2. using view() method\n",
    "re_tensor_2 = tensor.view(3, 2)\n",
    "\n",
    "print(re_tensor_1,\"\\n\\n\",re_tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39ba0d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]]) \n",
      "\n",
      " tensor([[1, 4, 7],\n",
      "        [2, 5, 8],\n",
      "        [3, 6, 9]])\n",
      "=======================\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) \n",
      "\n",
      " tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "# to transpose a tensor, using T attribute\n",
    "tensor_1 = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]])\n",
    "tensor_transposed_1 = tensor_1.T\n",
    "\n",
    "print(tensor_1,\"\\n\\n\",tensor_transposed_1)\n",
    "\n",
    "print(\"=======================\")\n",
    "\n",
    "# try anothor tensor\n",
    "tensor_2 = torch.tensor([[1, 2, 3],\n",
    "                         [4, 5, 6]])\n",
    "tensor_transposed_2 = tensor_2.T\n",
    "\n",
    "print(tensor_2, \"\\n\\n\", tensor_transposed_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eddfd2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[22, 28],\n",
      "        [49, 64]])\n",
      "=======================\n",
      "tensor([[22, 28],\n",
      "        [49, 64]])\n"
     ]
    }
   ],
   "source": [
    "# if we want to muptliply two tensors, there are two methods\n",
    "tensor_a = torch.tensor([[1, 2, 3],\n",
    "                         [4, 5, 6]])\n",
    "tensor_b = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]])\n",
    "\n",
    "# 1. using .matmul()\n",
    "tensor_c = tensor_a.matmul(tensor_b)\n",
    "print(tensor_c)\n",
    "\n",
    "print(\"=======================\")\n",
    "\n",
    "# 2. using @\n",
    "tensor_c = tensor_a@tensor_b\n",
    "print(tensor_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d295ed",
   "metadata": {},
   "source": [
    "## 大家都要學會的招數"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9938fd19",
   "metadata": {},
   "source": [
    "```.to()``` 可以讓張量運算指定到GPU上運行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a78c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x = x.to(\"cuda\")            # Move tensor to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65649c0",
   "metadata": {},
   "source": [
    "### 大家跑比賽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b766ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 3791.07 ms\n",
      "GPU time:795.06 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# 謝謝G學長教我怎麼算時間\n",
    "N = 8000\n",
    "\n",
    "tensor_a = torch.randn(N, N)\n",
    "tensor_b = torch.randn(N, N)\n",
    "# move to GPU\n",
    "tensor_a_GPU = tensor_a.to(\"cuda\")\n",
    "tensor_b_GPU = tensor_b.to(\"cuda\")\n",
    "\n",
    "# 預熱 (Warm-up)\n",
    "_ = tensor_a @ tensor_b \n",
    "_ = tensor_a_GPU @ tensor_b_GPU\n",
    "torch.cuda.synchronize()        # 等待預熱完成\n",
    "\n",
    "# ============================\n",
    "# CPU 系列\n",
    "# ============================\n",
    "start = time.time()\n",
    "\n",
    "result_CPU = tensor_a@tensor_b\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "cpu_time_ms = (end - start) * 1000  # s -> ms\n",
    "\n",
    "print(f\"CPU time: {cpu_time_ms:.2f} ms\")\n",
    "\n",
    "# ============================\n",
    "# GPU 系列\n",
    "# ============================\n",
    "# create events\n",
    "start_GPU = torch.cuda.Event(enable_timing=True)\n",
    "end_GPU = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start_GPU.record()\n",
    "\n",
    "result_GPU = tensor_a_GPU@tensor_b_GPU\n",
    "\n",
    "end_GPU.record()\n",
    "\n",
    "# 等待GPU跑完\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "gpu_time_ms = start_GPU.elapsed_time(end_GPU)\n",
    "\n",
    "print(f\"GPU time:{gpu_time_ms:.2f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
